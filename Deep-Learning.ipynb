{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE weights0: 8648.500000\n",
      "MSE weights1: 4038.500000\n"
     ]
    }
   ],
   "source": [
    "#Implementation of Forward Propagation algorithm\n",
    "#Use of activation function: capture non-linearities\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def pred(data, weights):\n",
    "    \n",
    "    node0_0_input = (data * weights['node0']).sum()\n",
    "    node0_0_output = max(node0_0_input, 0)\n",
    "    \n",
    "    node0_1_input = (data * weights['node1']).sum()\n",
    "    node0_1_output = max(node0_1_input, 0)\n",
    "    \n",
    "    hidden_0_out = np.array([node0_0_output, node0_1_output])\n",
    "\n",
    "    model_output = (hidden_0_out * weights['output']).sum()\n",
    "    \n",
    "    return(model_output)\n",
    "\n",
    "data = np.array([[2, 4], [3, -3], [0, 0], [6, 3]])\n",
    "actual = np.array([2,3,5,6])\n",
    "\n",
    "weights0 = {'node0': np.array([2, 4]),\n",
    "           'node1': np.array([4, -6]),\n",
    "           'output': np.array([1, 6])}\n",
    "\n",
    "weights1 = {'node0': np.array([-2, 4]),\n",
    "           'node1': np.array([3, -4]),\n",
    "           'output': np.array([1, 6])}\n",
    "\n",
    "results0 = []\n",
    "results1 = []\n",
    "for i in data:\n",
    "    results0.append(pred(i, weights0))\n",
    "    results1.append(pred(i, weights1))\n",
    "    \n",
    "mse0 = mean_squared_error(actual, results0)\n",
    "mse1 = mean_squared_error(actual, results1)\n",
    "\n",
    "print(\"MSE weights0: %f\" %mse0)\n",
    "print(\"MSE weights1: %f\" %mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculate slope for a weight\n",
    "#slope of loss function (weight into pred minus actual multiplied by value of neuron preceeding) * value of neuron/node\n",
    "#value of neuron * weight\n",
    "#slope of activation function * value\n",
    "\n",
    "# gradient = 2 * data * error (need some calculus to get this...chain rule)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#calculating error\n",
    "def err(data, actual, weights):\n",
    "    preds = (weights * data).sum()\n",
    "    error = preds - actual\n",
    "    return(error)\n",
    "\n",
    "#calculating mean squared error\n",
    "def fmse(data, actual, weights):\n",
    "    errors = err(data, actual, weights)\n",
    "    mse = np.mean(errors**2)\n",
    "    return(mse)\n",
    "\n",
    "#calculating slope\n",
    "def slope(data, actual, weights):\n",
    "    error = err(data, actual, weights)\n",
    "    slope = 2 * data * error\n",
    "    return(slope)\n",
    "\n",
    "n_iter = 20\n",
    "data = np.array([1, 2, 3])\n",
    "weights = np.array([0, 2, 1])\n",
    "actual = 0\n",
    "mse_hist = []\n",
    "\n",
    "# Iterate over the number of updates\n",
    "for i in range(n_iter):\n",
    "    # Calculate the slope: slope\n",
    "    slp = slope(data, actual, weights)\n",
    "    \n",
    "    # Update the weights: weights\n",
    "    weights = weights - 0.01 * slp\n",
    "    \n",
    "    # Calculate mse with new weights: mse\n",
    "    mse = fmse(data, actual, weights)\n",
    "    \n",
    "    # Append the mse to mse_hist\n",
    "    mse_hist.append(mse)\n",
    "\n",
    "# Plot the mse history\n",
    "plt.plot(mse_hist)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backpropagation process?\n",
    "#ascertain slope of loss function for each weight\n",
    "#perform forward propagation to calculate predictions and errors\n",
    "#predictions using forward propagation, you update the weights using backward propagation.\n",
    "#each iteration through training data is called epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n",
      "Epoch 1/10\n",
      "534/534 [==============================] - 0s 858us/step - loss: 30.9904\n",
      "Epoch 2/10\n",
      "534/534 [==============================] - 0s 65us/step - loss: 24.5819\n",
      "Epoch 3/10\n",
      "534/534 [==============================] - 0s 54us/step - loss: 22.9761\n",
      "Epoch 4/10\n",
      "534/534 [==============================] - 0s 50us/step - loss: 21.6685\n",
      "Epoch 5/10\n",
      "534/534 [==============================] - 0s 59us/step - loss: 21.6620\n",
      "Epoch 6/10\n",
      "534/534 [==============================] - 0s 59us/step - loss: 21.5653\n",
      "Epoch 7/10\n",
      "534/534 [==============================] - 0s 58us/step - loss: 20.9927\n",
      "Epoch 8/10\n",
      "534/534 [==============================] - 0s 46us/step - loss: 21.2405\n",
      "Epoch 9/10\n",
      "534/534 [==============================] - 0s 59us/step - loss: 20.7598\n",
      "Epoch 10/10\n",
      "534/534 [==============================] - 0s 51us/step - loss: 20.7941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc1fc7f160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "data = pd.read_csv('data/hourly_wages.csv')\n",
    "\n",
    "predictors = np.array(data.iloc[:,1:])\n",
    "target = np.array(data.iloc[:,0])\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "#first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "#second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compiling the model\n",
    "\n",
    "#1. optimizer control the learning rate. example ADAM. Note: make sure to standardize feature values so ADAM can perfrom better\n",
    "#2. Pick a loss model. MSE for regression. Keras for classification \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 315us/step - loss: 2.2362 - acc: 0.5903\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 55us/step - loss: 1.2361 - acc: 0.6038\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.7677 - acc: 0.6453\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 58us/step - loss: 0.7566 - acc: 0.6521\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.6135 - acc: 0.6846\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 53us/step - loss: 0.6145 - acc: 0.6869\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 0.6253 - acc: 0.6835\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 52us/step - loss: 0.6031 - acc: 0.6981\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 0.5966 - acc: 0.6992\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 52us/step - loss: 0.5928 - acc: 0.7015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc2110d5c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now onto classification problems\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "df = pd.read_csv('data/titanic_all_numeric.csv')\n",
    "\n",
    "predictors = np.array(df.iloc[:,1:])\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39712897 0.57074004 0.8044123  0.46715286 0.34581372 0.32716954\n",
      " 0.15186645 0.45437607 0.35719857 0.7300025  0.36736855 0.5206442\n",
      " 0.35075843 0.46251714 0.33493733 0.22186466 0.41501984 0.597984\n",
      " 0.21039395 0.5051329  0.8578857  0.37130395 0.15782246 0.4484864\n",
      " 0.44993567 0.2993445  0.7452693  0.5936936  0.3104829  0.8175021\n",
      " 0.4551204  0.51039743 0.2777781  0.39087182 0.4392369  0.818946\n",
      " 0.4200654  0.33568433 0.7445769  0.60536313 0.41655383 0.50320864\n",
      " 0.6201732  0.22183698 0.45352864 0.24063247 0.5525246  0.2475786\n",
      " 0.63305366 0.82228374 0.42495802 0.06677469 0.4798677  0.701175\n",
      " 0.5088373  0.46765605 0.9399705  0.4891966  0.48390675 0.2777781\n",
      " 0.27712417 0.44261807 0.52841973 0.5643645  0.48069978 0.35574993\n",
      " 0.40059575 0.73707896 0.35724902 0.47915637 0.36749533 0.70375085\n",
      " 0.27413297 0.22800134 0.52317    0.41676283 0.44750798 0.424376\n",
      " 0.33342895 0.82232857 0.6040301  0.31407863 0.46531525 0.40671432\n",
      " 0.36250135 0.52414304 0.45529467 0.6544924  0.5094857  0.6136362\n",
      " 0.29062295]\n"
     ]
    }
   ],
   "source": [
    "#testdata\n",
    "\n",
    "df1 = pd.read_csv('pred.csv')\n",
    "\n",
    "pred = np.array(df1)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predict = model.predict(pred)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "prob_surv = predict[:,1]\n",
    "\n",
    "# print prob_surv\n",
    "print(prob_surv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.7566\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.7537\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 79us/step - loss: 0.7508\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 74us/step - loss: 0.7481\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 80us/step - loss: 0.7455\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.7430\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.7405\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 55us/step - loss: 0.7382\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 76us/step - loss: 0.7359\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 62us/step - loss: 0.7338\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 615us/step - loss: 2.1057\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 62us/step - loss: 0.7909\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 62us/step - loss: 0.6564\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 64us/step - loss: 0.6613\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 66us/step - loss: 0.6097\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 73us/step - loss: 0.5981\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.5929\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.6231\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.5818\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 56us/step - loss: 0.5955\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 721us/step - loss: 6.0105\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 81us/step - loss: 6.1867\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 80us/step - loss: 6.1867\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 78us/step - loss: 6.1867\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 78us/step - loss: 6.1867\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 65us/step - loss: 6.1867\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 68us/step - loss: 6.1867\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 72us/step - loss: 6.1867\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 67us/step - loss: 6.1867\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 67us/step - loss: 6.1867\n"
     ]
    }
   ],
   "source": [
    "#Optimization and parameter tuning\n",
    "#dying-neuron: neuron takes less than zero value for all rows\n",
    "#vanishing gradient problem: when layers have smaller slopes(sometimes closer to zero) as we move backward in the network. this causes the backprop update to be zero\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "input_shape = (10,)\n",
    "\n",
    "def model_iter(input_shape = input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_l = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for i in lr_l:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%i )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = model_iter()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=i)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors,target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 1.1085 - acc: 0.6100 - val_loss: 0.9308 - val_acc: 0.4366\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 123us/step - loss: 0.6835 - acc: 0.6485 - val_loss: 0.7239 - val_acc: 0.6455\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 133us/step - loss: 0.7097 - acc: 0.6067 - val_loss: 0.5358 - val_acc: 0.7575\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 132us/step - loss: 0.6533 - acc: 0.6726 - val_loss: 0.5436 - val_acc: 0.7687\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 130us/step - loss: 0.6762 - acc: 0.6549 - val_loss: 0.5498 - val_acc: 0.7276\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 130us/step - loss: 0.6154 - acc: 0.6870 - val_loss: 0.5008 - val_acc: 0.7537\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - ETA: 0s - loss: 0.5798 - acc: 0.687 - 0s 141us/step - loss: 0.5723 - acc: 0.6982 - val_loss: 0.5117 - val_acc: 0.7948\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 120us/step - loss: 0.6140 - acc: 0.7079 - val_loss: 0.5992 - val_acc: 0.7388\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 132us/step - loss: 0.6611 - acc: 0.6629 - val_loss: 1.0300 - val_acc: 0.6493\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.6673 - acc: 0.6886 - val_loss: 0.5737 - val_acc: 0.7276\n"
     ]
    }
   ],
   "source": [
    "#validation dataset\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors,target,validation_split=0.3,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 2s 2ms/step - loss: 1.0414 - acc: 0.5923 - val_loss: 0.6072 - val_acc: 0.7015\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 136us/step - loss: 0.7481 - acc: 0.6292 - val_loss: 0.5613 - val_acc: 0.7164\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 150us/step - loss: 0.7044 - acc: 0.6822 - val_loss: 0.6691 - val_acc: 0.6828\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 151us/step - loss: 0.6481 - acc: 0.6838 - val_loss: 0.5336 - val_acc: 0.7313\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 165us/step - loss: 0.7796 - acc: 0.6629 - val_loss: 0.9651 - val_acc: 0.6530\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 163us/step - loss: 0.6273 - acc: 0.6838 - val_loss: 0.5277 - val_acc: 0.7612\n",
      "Epoch 7/30\n",
      "623/623 [==============================] - 0s 149us/step - loss: 0.6001 - acc: 0.6870 - val_loss: 0.4968 - val_acc: 0.7649\n",
      "Epoch 8/30\n",
      "623/623 [==============================] - 0s 170us/step - loss: 0.5460 - acc: 0.7271 - val_loss: 0.5455 - val_acc: 0.7127\n",
      "Epoch 9/30\n",
      "623/623 [==============================] - 0s 182us/step - loss: 0.5384 - acc: 0.7319 - val_loss: 0.5273 - val_acc: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc28b79b38>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what to do when good'ol optimization fails to improve performance\n",
    "\n",
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,validation_split=0.3,epochs=30,callbacks=[early_stopping_monitor])\n",
    "\n",
    "#stopped after 9 epochs because the performance wasn't improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#comparing two different models\n",
    "\n",
    "#model1 with 10 units\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "#model2 with 100 units\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the models\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model1_training = model1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model2_training = model2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model1_training.history['val_loss'], 'r', model2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to decide the architecture of the network\n",
    "# start simple, monitor the validation score, keep adding layer until the progress gets stagnant\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
